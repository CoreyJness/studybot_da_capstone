{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the functions we will be using during our model training: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create a loop to add the txt files into a data frame\n",
    "def txt_retrieval(folder_path):\n",
    "    qa = []\n",
    "    txt_files = [f for f in os.listdir(folder_path) if f.endswith(\".txt\")]\n",
    "    for file in txt_files:\n",
    "        file_path = os.path.join(folder_path, file) \n",
    "        df = pd.read_json(file_path) \n",
    "        df[\"source_file\"] = file  \n",
    "        qa.append(df)\n",
    "    return pd.concat(qa, ignore_index=True) if qa else pd.DataFrame()\n",
    "\n",
    "\n",
    "#Combine questions and answers to pass to the model\n",
    "def qa_pairs(questions, options):\n",
    "    pairs = []\n",
    "    for q, opts in zip(questions, options):\n",
    "        for opt in opts:\n",
    "            pairs.append((q,opt))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "##Use the tokenizer to encode the text\n",
    "def encode(data_component):\n",
    "    for i in data_component: \n",
    "        encoded_data = tokenizer(data_component, return_tensors='pt', padding=True)\n",
    "    return encoded_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the question sets that will be used to train the model.  The first dataset is the RACE dataseet, which consists of multiple choice questions separated between M (middle school) and H (high school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "middle = \"middle\"\n",
    "high = \"high\\high\"\n",
    "\n",
    "\n",
    "# Assign separate outputs based on the variable names\n",
    "m_qa = txt_retrieval(middle)\n",
    "h_qa = txt_retrieval(high)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the column names to see how the data is structured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['answers', 'options', 'questions', 'article', 'id', 'source_file'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_qa.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>options</th>\n",
       "      <th>questions</th>\n",
       "      <th>article</th>\n",
       "      <th>id</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>[affected only the companies doing business wi...</td>\n",
       "      <td>The Sherman Antitrust Act  _  .</td>\n",
       "      <td>One thinks of princes and presidents as some o...</td>\n",
       "      <td>high10024.txt</td>\n",
       "      <td>10024.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>[are more likely to exist in a competitive mar...</td>\n",
       "      <td>One might infer from this passage that lower p...</td>\n",
       "      <td>One thinks of princes and presidents as some o...</td>\n",
       "      <td>high10024.txt</td>\n",
       "      <td>10024.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>[believed that the trusts had little influence...</td>\n",
       "      <td>It seems likely that many Americans  _  .</td>\n",
       "      <td>One thinks of princes and presidents as some o...</td>\n",
       "      <td>high10024.txt</td>\n",
       "      <td>10024.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>[buy high-quality products, communicate with f...</td>\n",
       "      <td>Bargaining is a skill to   _  .</td>\n",
       "      <td>Everything in China is negotiable, so goes the...</td>\n",
       "      <td>high10042.txt</td>\n",
       "      <td>10042.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>[rising incomes, an increasing number of produ...</td>\n",
       "      <td>In China, the younger generation is losing int...</td>\n",
       "      <td>Everything in China is negotiable, so goes the...</td>\n",
       "      <td>high10042.txt</td>\n",
       "      <td>10042.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>C</td>\n",
       "      <td>[The sensor size., The zoom range., The shutte...</td>\n",
       "      <td>What will contribute to a satisfactory photo o...</td>\n",
       "      <td>If you are a traditional traveller who believe...</td>\n",
       "      <td>high15028.txt</td>\n",
       "      <td>15028.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>A</td>\n",
       "      <td>[How to choose ideal travel cameras?, How to p...</td>\n",
       "      <td>Which of the following can be the best title o...</td>\n",
       "      <td>If you are a traditional traveller who believe...</td>\n",
       "      <td>high15028.txt</td>\n",
       "      <td>15028.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>D</td>\n",
       "      <td>[A growth mindstet means no failure., People n...</td>\n",
       "      <td>What is the author's opinion of people' s mind...</td>\n",
       "      <td>Fixed or growth mindset -- which do you have?\\...</td>\n",
       "      <td>high15042.txt</td>\n",
       "      <td>15042.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>C</td>\n",
       "      <td>[You are clever., You are skillful., You have ...</td>\n",
       "      <td>Which judgment seems more encouraging?</td>\n",
       "      <td>Fixed or growth mindset -- which do you have?\\...</td>\n",
       "      <td>high15042.txt</td>\n",
       "      <td>15042.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>A</td>\n",
       "      <td>[Keeping on learning., Viewing ability as fail...</td>\n",
       "      <td>What do the growth-mindset  persons most advoc...</td>\n",
       "      <td>Fixed or growth mindset -- which do you have?\\...</td>\n",
       "      <td>high15042.txt</td>\n",
       "      <td>15042.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>817 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    answers                                            options  \\\n",
       "0         B  [affected only the companies doing business wi...   \n",
       "1         A  [are more likely to exist in a competitive mar...   \n",
       "2         D  [believed that the trusts had little influence...   \n",
       "3         C  [buy high-quality products, communicate with f...   \n",
       "4         A  [rising incomes, an increasing number of produ...   \n",
       "..      ...                                                ...   \n",
       "812       C  [The sensor size., The zoom range., The shutte...   \n",
       "813       A  [How to choose ideal travel cameras?, How to p...   \n",
       "814       D  [A growth mindstet means no failure., People n...   \n",
       "815       C  [You are clever., You are skillful., You have ...   \n",
       "816       A  [Keeping on learning., Viewing ability as fail...   \n",
       "\n",
       "                                             questions  \\\n",
       "0                      The Sherman Antitrust Act  _  .   \n",
       "1    One might infer from this passage that lower p...   \n",
       "2            It seems likely that many Americans  _  .   \n",
       "3                      Bargaining is a skill to   _  .   \n",
       "4    In China, the younger generation is losing int...   \n",
       "..                                                 ...   \n",
       "812  What will contribute to a satisfactory photo o...   \n",
       "813  Which of the following can be the best title o...   \n",
       "814  What is the author's opinion of people' s mind...   \n",
       "815             Which judgment seems more encouraging?   \n",
       "816  What do the growth-mindset  persons most advoc...   \n",
       "\n",
       "                                               article             id  \\\n",
       "0    One thinks of princes and presidents as some o...  high10024.txt   \n",
       "1    One thinks of princes and presidents as some o...  high10024.txt   \n",
       "2    One thinks of princes and presidents as some o...  high10024.txt   \n",
       "3    Everything in China is negotiable, so goes the...  high10042.txt   \n",
       "4    Everything in China is negotiable, so goes the...  high10042.txt   \n",
       "..                                                 ...            ...   \n",
       "812  If you are a traditional traveller who believe...  high15028.txt   \n",
       "813  If you are a traditional traveller who believe...  high15028.txt   \n",
       "814  Fixed or growth mindset -- which do you have?\\...  high15042.txt   \n",
       "815  Fixed or growth mindset -- which do you have?\\...  high15042.txt   \n",
       "816  Fixed or growth mindset -- which do you have?\\...  high15042.txt   \n",
       "\n",
       "    source_file  \n",
       "0     10024.txt  \n",
       "1     10024.txt  \n",
       "2     10024.txt  \n",
       "3     10042.txt  \n",
       "4     10042.txt  \n",
       "..          ...  \n",
       "812   15028.txt  \n",
       "813   15028.txt  \n",
       "814   15042.txt  \n",
       "815   15042.txt  \n",
       "816   15042.txt  \n",
       "\n",
       "[817 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_qa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the data into its components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_questions = m_qa.questions.values.tolist()\n",
    "h_questions = h_qa.questions.values.tolist()\n",
    "m_options = m_qa.options.values.tolist()\n",
    "h_options = h_qa.options.values.tolist()\n",
    "m_article = m_qa.article.values.tolist()\n",
    "h_article = h_qa.article.values.tolist()\n",
    "m_id = m_qa.id.values.tolist()\n",
    "h_id = h_qa.id.values.tolist()\n",
    "m_answers = m_qa.answers.values.tolist()\n",
    "h_answers = h_qa.answers.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Bert from transformers and use the tokenizer specialized for the model to input text as tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertConfig, BertModel, AutoModel, AutoTokenizer\n",
    "##bert = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "##tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "##m_qa_pairs = qa_pairs(m_questions, m_options)\n",
    "##m_qa_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode questions, option, and answer components.   Save the encoded QA inputs to avoid the time consumption required from the tokenization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##m_qa_inputs = encode(m_qa_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##torch.save(m_qa_inputs, \"m_qa_inputs.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for the correct answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##m_answers_inputs = encode(m_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##torch.save(m_answers_inputs, \"m_answers_inputs.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the readings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##m_readings_inputs = encode(m_article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##torch.save(m_readings_inputs, \"m_readings_inputs.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start training our model by using two Multi-Head Attention networks to compare the questions and the answer sequences.  We will first set up the training parameters for the networks. \n",
    "\n",
    "Sequence length is set to be the max size input in the high school dataset.  \n",
    "Batch Size is the number of times that the network will run through the data in a training session.\n",
    "Input dim is the vector dimension.  This sets the number of dimensions that the network uses.  \n",
    "D model is the output of attention model for all of the inputs\n",
    "m qa training is coming from the tokenized questions and answers that we saved earlier to the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3714)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_qa['article'].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 3714\n",
    "batch_size = 10\n",
    "input_dim = 500\n",
    "d_model = 512\n",
    "m_qa_training = torch.load(\"m_qa_inputs.pt\", weights_only=False)\n",
    "m_qa_training_parameters = torch.randn(input_dim, batch_size, sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the dimensions are equal.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 10, 3714])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_qa_training_parameters.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the Query Key Value processing layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv_layer = nn.Linear(input_dim , 3 * d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m qkv \u001b[38;5;241m=\u001b[39m qkv_layer(\u001b[43mx\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "qkv = qkv_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3714, 1536])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the eight attention heads, set up their dimensions, apply the qkv layer.  Reorder the data so it is inputed by batchsize, numheads sequence length, and head_dim by the QKV value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 8\n",
    "head_dim = d_model//num_heads\n",
    "qkv = qkv.reshape(batch_size, sequence_length, num_heads, 3*head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv.permute(0,2,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3714, 8, 192])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 3714, 8, 64]),\n",
       " torch.Size([10, 3714, 8, 64]),\n",
       " torch.Size([10, 3714, 8, 64]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, k, v = qkv.chunk(3, dim=-1)\n",
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{self attention} = \\text{softmax} \\left( \\frac{Q K^T}{\\sqrt{d_k}} + M \\right)\n",
    "$$\n",
    "\n",
    "Then, the updated value matrix is obtained as:\n",
    "\n",
    "$$\n",
    "\\text{new } V = \\text{self attention} \\cdot V\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3714, 8, 8])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "d_k = q.size()[-1]\n",
    "scaled = torch.matmul(q, k.transpose(-2,-1)) / math.sqrt(d_k)\n",
    "scaled.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the masking layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.full(scaled.size() , float('-inf'))\n",
    "mask = torch.triu(mask, diagonal=1)\n",
    "mask[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2609,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "        [ 0.1441, -0.4110,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "        [-0.1988,  0.2117,  0.3794,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "        [-0.2249,  0.1411,  0.4591, -0.4204,    -inf,    -inf,    -inf,    -inf],\n",
       "        [ 0.1424, -0.7792,  0.0121, -0.4248, -0.0755,    -inf,    -inf,    -inf],\n",
       "        [ 0.0371, -0.2330, -0.2173, -0.1348,  0.0426,  0.0537,    -inf,    -inf],\n",
       "        [ 0.2725, -0.0192, -0.2573,  0.0139,  0.0182,  0.3217, -0.1797,    -inf],\n",
       "        [ 0.3331, -0.4011, -0.7940,  0.3819,  0.3435,  0.2920,  1.2055, -0.2377]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scaled + mask)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim = -1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, attention = scaled_dot_product(q, k, v, mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3714, 8, 8])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3714, 8, 64])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3714, 512])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = values.reshape(batch_size, sequence_length, num_heads * head_dim)\n",
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = nn.Linear(d_model, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = linear_layer(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3714, 512])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
