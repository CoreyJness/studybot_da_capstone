{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìò Introduction\n",
    "\n",
    "This notebook supports the capstone project **\"Question Difficulty Classification\"**, which explores the development of a machine learning model to predict the **grade level** (3rd‚Äì12th) of input questions. The model seeks to align questions with **Common Core State Standards (CCSS)** in order to predict grade level.\n",
    "\n",
    "Inspired by the paper *\"Question Difficulty Estimation Based on Attention Model for Question Answering\"*, the architecture extends BERT using a **custom Dual Attention Mechanism** (`DualBertModel`) to better capture the semantic complexity of questions.\n",
    "\n",
    "This notebook walks through:\n",
    "- Loading and preprocessing a custom educational dataset (`QxGrade`)\n",
    "- Initializing and training a dual-attention BERT-based classifier\n",
    "- Evaluating performance on unseen grade-level questions\n",
    "- Saving the model for deployment in a **Streamlit app**\n",
    "\n",
    "The project is implemented primarily in **PyTorch**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers.models.bert.modeling_bert import BertIntermediate, BertOutput, BertEncoder, BertSelfAttention, BertSelfOutput, BertModel, BertConfig, BertPooler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Functions\n",
    "Here are the training and testing functions used during data preprocessing, training, and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, input_ids, attention_mask, train_loader, criterion, optimizer, epochs):\n",
    "    running_acc = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for input_ids, attention_mask, labels in train_loader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass -- Passes the questions through the Neural Network then tests them against the correct labels\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Accuracy\n",
    "            _, predicted_labels = torch.max(outputs, dim=1)\n",
    "            correct_predictions = (predicted_labels == labels).sum().item()\n",
    "            total_correct += correct_predictions\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            # Backward pass -- Adjusts model to make better predictions\n",
    "            optimizer.zero_grad()  #Zero out the gradients from the previous batch\n",
    "            loss.backward()  # Backpropagate the loss to compute gradients\n",
    "            optimizer.step()  #Perform a single step to update parameters\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Epoch metrics\n",
    "        epoch_loss = total_loss / len(train_loader)\n",
    "        epoch_acc = total_correct / total_samples\n",
    "        running_acc.append(epoch_acc)\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "    # Plotting after training\n",
    "    df_acc = pd.DataFrame({'Epochs': range(1, epochs + 1), 'Accuracy': running_acc})\n",
    "    df_acc.plot(x='Epochs', y='Accuracy', kind='line', title='Training Accuracy Over Epochs', grid=True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test(model, test_loader, criterion, device, epochs):\n",
    "    running_test_acc = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with torch.no_grad():               ##We don't want the model training on test data\n",
    "            for input_ids, attention_mask, labels in test_loader:\n",
    "                input_ids = input_ids.to(device)\n",
    "                attention_mask = attention_mask.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Accuracy\n",
    "                _, predicted_labels = torch.max(outputs, dim=1)\n",
    "                correct_predictions = (predicted_labels == labels).sum().item()\n",
    "                total_correct += correct_predictions\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        # Epoch metrics\n",
    "        epoch_loss = total_loss / len(test_loader)\n",
    "        epoch_acc = total_correct / total_samples\n",
    "        running_test_acc.append(epoch_acc)\n",
    "        print(f'[Test] Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "    # Plotting after testing\n",
    "    df_test = pd.DataFrame({'Epochs': range(1, epochs + 1), 'Accuracy': running_test_acc})\n",
    "    df_test.plot(x='Epochs', y='Accuracy', kind='line', title='Testing Accuracy Over Epochs', grid=True)\n",
    "    plt.show()\n",
    "    \n",
    "    return df_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Neural Network Modifications\n",
    "Here are the modifications made to the Bert model to implement Dual Multihead Attention Mechanisms and multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implements dual self-attention: two separate attention heads run in parallel and their outputs are combined\n",
    "class DualBertAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.attention1 = BertSelfAttention(config)\n",
    "        self.attention2 = BertSelfAttention(config)\n",
    "        self.output1 = BertSelfOutput(config)\n",
    "        self.output2 = BertSelfOutput(config)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask=None, head_mask=None):\n",
    "        attn_output1 = self.attention1(hidden_states, attention_mask, head_mask)[0]\n",
    "        attn_output1 = self.output1(attn_output1, hidden_states)\n",
    "\n",
    "        attn_output2 = self.attention2(hidden_states, attention_mask, head_mask)[0]\n",
    "        attn_output2 = self.output2(attn_output2, hidden_states)\n",
    "\n",
    "        # Combine the two attention outputs using ReLU activation (replacing any negative values with 0)\n",
    "        dual_attention_output = F.relu(attn_output1 + attn_output2)\n",
    "        return dual_attention_output\n",
    "\n",
    "\n",
    "## Wraps DualBertAttention in a full transformer layer with intermediate and output sublayers\n",
    "class DualBertLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.attention = DualBertAttention(config)\n",
    "        self.intermediate = BertIntermediate(config)\n",
    "        self.output = BertOutput(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        past_key_value=None,\n",
    "        output_attentions=False,\n",
    "    ):\n",
    "        attention_output = self.attention(hidden_states, attention_mask, head_mask)\n",
    "        intermediate_output = self.intermediate(attention_output)\n",
    "        layer_output = self.output(intermediate_output, attention_output)\n",
    "        return (layer_output,)\n",
    "\n",
    "\n",
    "## Stacks multiple DualBertLayer modules to form the full transformer encoder\n",
    "class DualBertEncoder(BertEncoder):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.layer = nn.ModuleList([DualBertLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "\n",
    "\n",
    "## Replaces the standard BERT encoder with the DualBertEncoder while keeping pooling layer\n",
    "class DualBertModel(BertModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.encoder = DualBertEncoder(config)\n",
    "        self.pooler = BertPooler(config)\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, **kwargs):\n",
    "        # Run the standard BERT forward pass using the modified encoder\n",
    "        outputs = super().forward(input_ids=input_ids,\n",
    "                                  attention_mask=attention_mask,\n",
    "                                  token_type_ids=token_type_ids,\n",
    "                                  **kwargs)\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "        pooled_output = self.pooler(sequence_output)\n",
    "\n",
    "        return (sequence_output, pooled_output)\n",
    "\n",
    "\n",
    "## Adds a classification head on top of the DualBertModel for text classification\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, hidden_dim=64, output_dim=6):\n",
    "        super().__init__()\n",
    "        self.bert = bert_model \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.bert.config.hidden_size, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_embedding = outputs[0][:, 0, :]  # Take [CLS] token's embedding\n",
    "        return self.classifier(cls_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóÉÔ∏è Dataset Import\n",
    "Import the question sets that will be used to train the model.  The QxGrade_dataset is a set of 26k questions scraped from pdf textbooks.  These textbooks were chosen based on alignment with Common Core State Standards to identify a framework that we can use when training the model with additional data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('QxGrade_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade Distribution:\n",
      " Grade\n",
      "3      418\n",
      "4     1191\n",
      "5     1658\n",
      "6      549\n",
      "7     1153\n",
      "8     1805\n",
      "9     8668\n",
      "10    2704\n",
      "11    7288\n",
      "12    1125\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "grade_counts = df['Grade'].value_counts().sort_index()\n",
    "print(\"Grade Distribution:\\n\", grade_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two most important columns we will be using and labeling are Grade and Question.  Using the .values and .tolist function here we are adding all of the grade options (3-12) to the grades function.  We are doing the same with all of the question values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.question.values.tolist()  ##X is questions\n",
    "y = df.Grade.astype(str).tolist() ##Y is answers\n",
    "\n",
    "num_classes = len(set(y))  ##This sets up the classification options (3rd-12th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use train_test_split to separate the value for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)  ##This is the only place where we use SciKit learn instead of pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  ##Set the device to GPU so we can train the model on the GPU\n",
    "\n",
    "# Tokenize training and test sets\n",
    "x_train_encodings = tokenizer(x_train, padding=True, truncation=True, return_tensors='pt', max_length=32)\n",
    "x_test_encodings = tokenizer(x_test, padding=True, truncation=True, return_tensors='pt', max_length=32)\n",
    "\n",
    "# Extract input IDs and attention masks\n",
    "input_ids_train = x_train_encodings[\"input_ids\"].to(device)\n",
    "attention_mask_train = x_train_encodings[\"attention_mask\"].to(device)\n",
    "\n",
    "input_ids_test = x_test_encodings[\"input_ids\"].to(device)\n",
    "attention_mask_test = x_test_encodings[\"attention_mask\"].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ints = [int(label) -3 for label in y_train] #Get grades below ten and change them to ints\n",
    "y_test_ints = [int(label) -3 for label in y_test]\n",
    "y_train_tensor = torch.tensor(y_train_ints)\n",
    "y_test_tensor = torch.tensor(y_test_ints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Build Custom BERT\n",
    "Using the network we created, instantiate our version of bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base BERT config and model\n",
    "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "dual_bert = DualBertModel(config)\n",
    "\n",
    "# Load pretrained BERT model\n",
    "pretrained_bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Copy embeddings and pooler\n",
    "dual_bert.embeddings = pretrained_bert.embeddings\n",
    "dual_bert.pooler = pretrained_bert.pooler\n",
    "\n",
    "# Build classifier\n",
    "bert_classifier = BertClassifier(dual_bert, hidden_dim=64, output_dim=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Set Hyperparameters\n",
    "Create the hyperparameters.  You can tinker with training times, sizes, and number of loops here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs = 20 ##How many times we go through the loop\n",
    "test_epochs = 5\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  ##This compares the predicted answer with the correct answer\n",
    "optimizer = torch.optim.Adam(bert_classifier.parameters(), lr=2e-5)  ##This is the function that controls how quickly the model learns by adjusting its parameters\n",
    "\n",
    "sequence_length = 32   ## Maximum length of tokens to be used at a time\n",
    "batch_size = 32  ##The number of training examples in one forward/backward pass\n",
    "input_dim = 512  ##The total number of dimension we will allow the model to use for calculation\n",
    "d_model = 512  ##Number of expected features, set to default recommended by pytorch\n",
    "\n",
    "\n",
    "test_dataset = TensorDataset(input_ids_test, attention_mask_test, y_test_tensor)    ##This separates the dataset into test and training sets.\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_dataset = TensorDataset(input_ids_train, attention_mask_train, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "in_features = input_ids_train.shape[1]   ##in_features are what we are passing to the classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è CUDA Troubleshooting\n",
    "If your CUDA is not available, this block will tell you.  The training loop will not work on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available?  True\n",
      "Device name:     NVIDIA GeForce RTX 4070 Ti\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"CUDA available? \", torch.cuda.is_available())\n",
    "print(\"Device name:    \", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Model Training\n",
    "Use Bert to classify the data --  The training loop takes around 1min per epoch at current hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.4273, Accuracy: 0.5319\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    bert_classifier,\n",
    "    input_ids_train,\n",
    "    attention_mask_train,\n",
    "    train_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    train_epochs\n",
    ")\n",
    "\n",
    "torch.save(bert_classifier.state_dict(), 'Bert_Classifier.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild full model\n",
    "bert_base = DualBertModel(config)\n",
    "bert_classifier = BertClassifier(bert_model=bert_base, hidden_dim=64, output_dim=num_classes)\n",
    "\n",
    "# Load the model state dict\n",
    "bert_classifier.load_state_dict(torch.load(\"bert_classifier.pt\", map_location=device))\n",
    "\n",
    "# Move to device and set to eval mode\n",
    "bert_classifier.to(device)\n",
    "bert_classifier.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_classifier.eval()\n",
    "test(bert_classifier, test_loader, criterion, device, test_epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Conclusions\n",
    "\n",
    "- A model can be successfully trained to classify questions by grade level in alignment with the Common Core State Standards (CCSS).\n",
    "\n",
    "- Expanding the dataset with greater variety and sourcing material from a wider range of educational companies is likely to significantly improve model performance.\n",
    "\n",
    "- Multiple rounds of testing with the current architecture consistently show an accuracy of approximately 70%.\n",
    "\n",
    "- While the model is functional in its current form, further improvements in accuracy and confidence would be necessary before deployment in a professional or production environment. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
